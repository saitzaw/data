{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ceecda5-1af4-447a-b804-c3522837088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "677abec3-e843-43c8-9c81-abaa615723b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/site-packages (1.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "203e84a4-c0f6-4ae6-9607-6dfd33afa32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"/opt/workspace\")\n",
    "from load_env import env_parameter\n",
    "\n",
    "# Load from .env\n",
    "env_vars = env_parameter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "029c5349-d082-45ae-b251-4857e5f685b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdbc_url = env_vars[\"jdbc_url\"]\n",
    "db_user = env_vars[\"db_user\"]\n",
    "db_password = env_vars[\"db_password\"]\n",
    "spark_master = env_vars[\"spark_master\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7085cbbd-a37a-481e-8db2-e741ea147b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92096e4a-84b7-4171-823b-3e3e82aec6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.postgresql#postgresql added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-75bc2518-3167-47f4-a6da-90f50876389b;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.postgresql#postgresql;42.5.0 in central\n",
      "\tfound org.checkerframework#checker-qual;3.5.0 in central\n",
      "downloading https://repo1.maven.org/maven2/org/postgresql/postgresql/42.5.0/postgresql-42.5.0.jar ...\n",
      "\t[SUCCESSFUL ] org.postgresql#postgresql;42.5.0!postgresql.jar (1534ms)\n",
      "downloading https://repo1.maven.org/maven2/org/checkerframework/checker-qual/3.5.0/checker-qual-3.5.0.jar ...\n",
      "\t[SUCCESSFUL ] org.checkerframework#checker-qual;3.5.0!checker-qual.jar (454ms)\n",
      ":: resolution report :: resolve 2001ms :: artifacts dl 1995ms\n",
      "\t:: modules in use:\n",
      "\torg.checkerframework#checker-qual;3.5.0 from central in [default]\n",
      "\torg.postgresql#postgresql;42.5.0 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   2   |   2   |   0   ||   2   |   2   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-75bc2518-3167-47f4-a6da-90f50876389b\n",
      "\tconfs: [default]\n",
      "\t2 artifacts copied, 0 already retrieved (1231kB/10ms)\n",
      "25/06/05 17:26:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Start Spark session with PostgreSQL JDBC driver\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ReadCRM\") \\\n",
    "    .master(spark_master) \\\n",
    "    .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.5.0\") \\\n",
    "    .config(\"spark.eventLog.enabled\", \"true\") \\\n",
    "    .config(\"spark.eventLog.dir\", \"file:/opt/spark-events\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe2b8008-d56f-4463-b536-6f94da0c2db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdbc_properties = {\n",
    "    \"user\": db_user,\n",
    "    \"password\": db_password,\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d6ae993-4ef3-42ff-a901-e88c7ecf04c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+-------------+-------------+--------+--------------------+-------------+--------------------+--------------------+\n",
      "| id|             name|     industry|       region|   phone|             website|         tags|            metadata|          created_at|\n",
      "+---+-----------------+-------------+-------------+--------+--------------------+-------------+--------------------+--------------------+\n",
      "|  1|Northwind Traders|       Retail|North America|555-1001|https://northwind...|[active, key]|{\"customer_tier\":...|2025-06-02 17:19:...|\n",
      "|  2|      Contoso Ltd|   Technology|       Europe|555-1002| https://contoso.com|   [prospect]|{\"platform\": \"Azu...|2025-06-02 17:19:...|\n",
      "|  3|  Adventure Works|Manufacturing|         Asia|555-1003|https://adventure...|        [new]|{\"needs\": \"IoT in...|2025-06-02 17:19:...|\n",
      "+---+-----------------+-------------+-------------+--------+--------------------+-------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.jdbc(url=jdbc_url, table=\"customers\", properties=jdbc_properties)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c2ac998-9d3d-42ad-86e3-0a55a4e29139",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69823d0e-5ac8-462e-a809-4113508a619a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
